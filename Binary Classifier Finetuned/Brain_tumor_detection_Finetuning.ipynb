{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PJD2Td3nNdca"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the zip file contents"
      ],
      "metadata": {
        "id": "8LttIzuKhmGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_zip = '/content/Brain_tumor.zip'\n",
        "data_dir = '/content/data/'\n",
        "zip_file = zipfile.ZipFile(data_zip,'r')\n",
        "zip_file.extractall(data_dir)"
      ],
      "metadata": {
        "id": "HkYqQrXjNfwh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the 'train' and 'val' folders"
      ],
      "metadata": {
        "id": "nxlUw-oHhuy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(os.path.join(data_dir,'train'))\n",
        "os.mkdir(os.path.join(data_dir,'val'))"
      ],
      "metadata": {
        "id": "761CYkdwNhtS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the class(yes / no) sub-folders in train and val folders"
      ],
      "metadata": {
        "id": "0nh0vrXihuEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = '/content/data/train'\n",
        "data_train_no = os.path.join(data_train,'no')\n",
        "os.mkdir(data_train_no)\n",
        "data_train_yes = os.path.join(data_train,'yes')\n",
        "os.mkdir(data_train_yes)\n",
        "data_val = '/content/data/val'\n",
        "data_val_no = os.path.join(data_val,'no')\n",
        "os.mkdir(data_val_no)\n",
        "data_val_yes = os.path.join(data_val,'yes')\n",
        "os.mkdir(data_val_yes)"
      ],
      "metadata": {
        "id": "W6umBcyuNjgy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset"
      ],
      "metadata": {
        "id": "s6L5t2mkiFX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = 0.8\n",
        "\n",
        "no_size = len(os.listdir('/content/data/brain_tumor_dataset/no'))\n",
        "yes_size = len(os.listdir('/content/data/brain_tumor_dataset/yes'))\n",
        "\n",
        "for i,img in enumerate(glob.glob(\"/content/data/brain_tumor_dataset/no/*\")):\n",
        "  if(i < no_size*split):\n",
        "    print(i,img)\n",
        "    shutil.move(img,data_train_no)\n",
        "  else:\n",
        "    shutil.move(img,data_val_no)\n",
        "\n",
        "for i,img in enumerate(glob.glob(\"/content/data/brain_tumor_dataset/yes/*\")):\n",
        "  if(i < yes_size*split):\n",
        "    print(i,img)\n",
        "    shutil.move(img,data_train_yes)\n",
        "  else:\n",
        "    shutil.move(img,data_val_yes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xznhfy3VN8_z",
        "outputId": "fb13a49f-1114-4b1a-fb17-32ad1327c8fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 /content/data/brain_tumor_dataset/no/no 100.jpg\n",
            "1 /content/data/brain_tumor_dataset/no/no 6.jpg\n",
            "2 /content/data/brain_tumor_dataset/no/6 no.jpg\n",
            "3 /content/data/brain_tumor_dataset/no/22 no.jpg\n",
            "4 /content/data/brain_tumor_dataset/no/25 no.jpg\n",
            "5 /content/data/brain_tumor_dataset/no/34 no.jpg\n",
            "6 /content/data/brain_tumor_dataset/no/18 no.jpg\n",
            "7 /content/data/brain_tumor_dataset/no/no 923.jpg\n",
            "8 /content/data/brain_tumor_dataset/no/no 89.jpg\n",
            "9 /content/data/brain_tumor_dataset/no/no 10.jpg\n",
            "10 /content/data/brain_tumor_dataset/no/No12.jpg\n",
            "11 /content/data/brain_tumor_dataset/no/47 no.jpg\n",
            "12 /content/data/brain_tumor_dataset/no/8 no.jpg\n",
            "13 /content/data/brain_tumor_dataset/no/No14.jpg\n",
            "14 /content/data/brain_tumor_dataset/no/44no.jpg\n",
            "15 /content/data/brain_tumor_dataset/no/no.jpg\n",
            "16 /content/data/brain_tumor_dataset/no/N17.jpg\n",
            "17 /content/data/brain_tumor_dataset/no/30 no.jpg\n",
            "18 /content/data/brain_tumor_dataset/no/no 8.jpg\n",
            "19 /content/data/brain_tumor_dataset/no/no 90.jpg\n",
            "20 /content/data/brain_tumor_dataset/no/23 no.jpg\n",
            "21 /content/data/brain_tumor_dataset/no/no 99.jpg\n",
            "22 /content/data/brain_tumor_dataset/no/13 no.jpg\n",
            "23 /content/data/brain_tumor_dataset/no/no 97.jpg\n",
            "24 /content/data/brain_tumor_dataset/no/26 no.jpg\n",
            "25 /content/data/brain_tumor_dataset/no/35 no.jpg\n",
            "26 /content/data/brain_tumor_dataset/no/36 no.jpg\n",
            "27 /content/data/brain_tumor_dataset/no/4 no.jpg\n",
            "28 /content/data/brain_tumor_dataset/no/N21.jpg\n",
            "29 /content/data/brain_tumor_dataset/no/no 94.jpg\n",
            "30 /content/data/brain_tumor_dataset/no/N20.JPG\n",
            "31 /content/data/brain_tumor_dataset/no/No22.jpg\n",
            "32 /content/data/brain_tumor_dataset/no/No15.jpg\n",
            "33 /content/data/brain_tumor_dataset/no/1 no.jpeg\n",
            "34 /content/data/brain_tumor_dataset/no/no 1.jpg\n",
            "35 /content/data/brain_tumor_dataset/no/no 9.png\n",
            "36 /content/data/brain_tumor_dataset/no/32 no.jpg\n",
            "37 /content/data/brain_tumor_dataset/no/45 no.jpg\n",
            "38 /content/data/brain_tumor_dataset/no/no 5.jpeg\n",
            "39 /content/data/brain_tumor_dataset/no/No16.jpg\n",
            "40 /content/data/brain_tumor_dataset/no/no 96.jpg\n",
            "41 /content/data/brain_tumor_dataset/no/N15.jpg\n",
            "42 /content/data/brain_tumor_dataset/no/39 no.jpg\n",
            "43 /content/data/brain_tumor_dataset/no/5 no.jpg\n",
            "44 /content/data/brain_tumor_dataset/no/no 92.jpg\n",
            "45 /content/data/brain_tumor_dataset/no/no 3.jpg\n",
            "46 /content/data/brain_tumor_dataset/no/no 98.jpg\n",
            "47 /content/data/brain_tumor_dataset/no/9 no.jpg\n",
            "48 /content/data/brain_tumor_dataset/no/N2.JPG\n",
            "49 /content/data/brain_tumor_dataset/no/43 no.jpg\n",
            "50 /content/data/brain_tumor_dataset/no/2 no.jpeg\n",
            "51 /content/data/brain_tumor_dataset/no/24 no.jpg\n",
            "52 /content/data/brain_tumor_dataset/no/N19.JPG\n",
            "53 /content/data/brain_tumor_dataset/no/10 no.jpg\n",
            "54 /content/data/brain_tumor_dataset/no/No20.jpg\n",
            "55 /content/data/brain_tumor_dataset/no/N5.jpg\n",
            "56 /content/data/brain_tumor_dataset/no/no 4.jpg\n",
            "57 /content/data/brain_tumor_dataset/no/N11.jpg\n",
            "58 /content/data/brain_tumor_dataset/no/12 no.jpg\n",
            "59 /content/data/brain_tumor_dataset/no/37 no.jpg\n",
            "60 /content/data/brain_tumor_dataset/no/no 95.jpg\n",
            "61 /content/data/brain_tumor_dataset/no/38 no.jpg\n",
            "62 /content/data/brain_tumor_dataset/no/40 no.jpg\n",
            "63 /content/data/brain_tumor_dataset/no/33 no.jpg\n",
            "64 /content/data/brain_tumor_dataset/no/N16.jpg\n",
            "65 /content/data/brain_tumor_dataset/no/21 no.jpg\n",
            "66 /content/data/brain_tumor_dataset/no/42 no.jpg\n",
            "67 /content/data/brain_tumor_dataset/no/28 no.jpg\n",
            "68 /content/data/brain_tumor_dataset/no/no 2.jpg\n",
            "69 /content/data/brain_tumor_dataset/no/No21.jpg\n",
            "70 /content/data/brain_tumor_dataset/no/N6.jpg\n",
            "71 /content/data/brain_tumor_dataset/no/46 no.jpg\n",
            "72 /content/data/brain_tumor_dataset/no/49 no.jpg\n",
            "73 /content/data/brain_tumor_dataset/no/19 no.jpg\n",
            "74 /content/data/brain_tumor_dataset/no/No13.jpg\n",
            "75 /content/data/brain_tumor_dataset/no/7 no.jpg\n",
            "76 /content/data/brain_tumor_dataset/no/31 no.jpg\n",
            "77 /content/data/brain_tumor_dataset/no/20 no.jpg\n",
            "78 /content/data/brain_tumor_dataset/no/3 no.jpg\n",
            "0 /content/data/brain_tumor_dataset/yes/Y147.JPG\n",
            "1 /content/data/brain_tumor_dataset/yes/Y4.jpg\n",
            "2 /content/data/brain_tumor_dataset/yes/Y77.jpg\n",
            "3 /content/data/brain_tumor_dataset/yes/Y39.jpg\n",
            "4 /content/data/brain_tumor_dataset/yes/Y167.JPG\n",
            "5 /content/data/brain_tumor_dataset/yes/Y54.jpg\n",
            "6 /content/data/brain_tumor_dataset/yes/Y156.JPG\n",
            "7 /content/data/brain_tumor_dataset/yes/Y23.JPG\n",
            "8 /content/data/brain_tumor_dataset/yes/Y66.JPG\n",
            "9 /content/data/brain_tumor_dataset/yes/Y47.JPG\n",
            "10 /content/data/brain_tumor_dataset/yes/Y7.jpg\n",
            "11 /content/data/brain_tumor_dataset/yes/Y182.JPG\n",
            "12 /content/data/brain_tumor_dataset/yes/Y165.JPG\n",
            "13 /content/data/brain_tumor_dataset/yes/Y10.jpg\n",
            "14 /content/data/brain_tumor_dataset/yes/Y26.jpg\n",
            "15 /content/data/brain_tumor_dataset/yes/Y28.jpg\n",
            "16 /content/data/brain_tumor_dataset/yes/Y9.jpg\n",
            "17 /content/data/brain_tumor_dataset/yes/Y254.jpg\n",
            "18 /content/data/brain_tumor_dataset/yes/Y248.JPG\n",
            "19 /content/data/brain_tumor_dataset/yes/Y19.JPG\n",
            "20 /content/data/brain_tumor_dataset/yes/Y92.png\n",
            "21 /content/data/brain_tumor_dataset/yes/Y162.jpg\n",
            "22 /content/data/brain_tumor_dataset/yes/Y18.JPG\n",
            "23 /content/data/brain_tumor_dataset/yes/Y16.JPG\n",
            "24 /content/data/brain_tumor_dataset/yes/Y82.jpg\n",
            "25 /content/data/brain_tumor_dataset/yes/Y53.jpg\n",
            "26 /content/data/brain_tumor_dataset/yes/Y35.jpg\n",
            "27 /content/data/brain_tumor_dataset/yes/Y29.jpg\n",
            "28 /content/data/brain_tumor_dataset/yes/Y36.JPG\n",
            "29 /content/data/brain_tumor_dataset/yes/Y44.JPG\n",
            "30 /content/data/brain_tumor_dataset/yes/Y252.jpg\n",
            "31 /content/data/brain_tumor_dataset/yes/Y74.jpg\n",
            "32 /content/data/brain_tumor_dataset/yes/Y104.jpg\n",
            "33 /content/data/brain_tumor_dataset/yes/Y146.JPG\n",
            "34 /content/data/brain_tumor_dataset/yes/Y31.jpg\n",
            "35 /content/data/brain_tumor_dataset/yes/Y86.JPG\n",
            "36 /content/data/brain_tumor_dataset/yes/Y69.jpg\n",
            "37 /content/data/brain_tumor_dataset/yes/Y75.JPG\n",
            "38 /content/data/brain_tumor_dataset/yes/Y17.jpg\n",
            "39 /content/data/brain_tumor_dataset/yes/Y73.jpg\n",
            "40 /content/data/brain_tumor_dataset/yes/Y96.jpg\n",
            "41 /content/data/brain_tumor_dataset/yes/Y8.jpg\n",
            "42 /content/data/brain_tumor_dataset/yes/Y192.JPG\n",
            "43 /content/data/brain_tumor_dataset/yes/Y256.JPG\n",
            "44 /content/data/brain_tumor_dataset/yes/Y114.JPG\n",
            "45 /content/data/brain_tumor_dataset/yes/Y6.jpg\n",
            "46 /content/data/brain_tumor_dataset/yes/Y65.JPG\n",
            "47 /content/data/brain_tumor_dataset/yes/Y38.jpg\n",
            "48 /content/data/brain_tumor_dataset/yes/Y153.jpg\n",
            "49 /content/data/brain_tumor_dataset/yes/Y42.jpg\n",
            "50 /content/data/brain_tumor_dataset/yes/Y183.jpg\n",
            "51 /content/data/brain_tumor_dataset/yes/Y169.jpg\n",
            "52 /content/data/brain_tumor_dataset/yes/Y95.jpg\n",
            "53 /content/data/brain_tumor_dataset/yes/Y258.JPG\n",
            "54 /content/data/brain_tumor_dataset/yes/Y244.JPG\n",
            "55 /content/data/brain_tumor_dataset/yes/Y46.jpg\n",
            "56 /content/data/brain_tumor_dataset/yes/Y67.JPG\n",
            "57 /content/data/brain_tumor_dataset/yes/Y79.jpg\n",
            "58 /content/data/brain_tumor_dataset/yes/Y111.JPG\n",
            "59 /content/data/brain_tumor_dataset/yes/Y91.jpg\n",
            "60 /content/data/brain_tumor_dataset/yes/Y49.JPG\n",
            "61 /content/data/brain_tumor_dataset/yes/Y60.jpg\n",
            "62 /content/data/brain_tumor_dataset/yes/Y188.jpg\n",
            "63 /content/data/brain_tumor_dataset/yes/Y107.jpg\n",
            "64 /content/data/brain_tumor_dataset/yes/Y184.JPG\n",
            "65 /content/data/brain_tumor_dataset/yes/Y257.jpg\n",
            "66 /content/data/brain_tumor_dataset/yes/Y158.JPG\n",
            "67 /content/data/brain_tumor_dataset/yes/Y250.jpg\n",
            "68 /content/data/brain_tumor_dataset/yes/Y70.jpg\n",
            "69 /content/data/brain_tumor_dataset/yes/Y108.jpg\n",
            "70 /content/data/brain_tumor_dataset/yes/Y20.jpg\n",
            "71 /content/data/brain_tumor_dataset/yes/Y25.jpg\n",
            "72 /content/data/brain_tumor_dataset/yes/Y148.JPG\n",
            "73 /content/data/brain_tumor_dataset/yes/Y59.JPG\n",
            "74 /content/data/brain_tumor_dataset/yes/Y62.jpg\n",
            "75 /content/data/brain_tumor_dataset/yes/Y170.JPG\n",
            "76 /content/data/brain_tumor_dataset/yes/Y97.JPG\n",
            "77 /content/data/brain_tumor_dataset/yes/Y37.jpg\n",
            "78 /content/data/brain_tumor_dataset/yes/Y15.jpg\n",
            "79 /content/data/brain_tumor_dataset/yes/Y103.jpg\n",
            "80 /content/data/brain_tumor_dataset/yes/Y90.jpg\n",
            "81 /content/data/brain_tumor_dataset/yes/Y32.jpg\n",
            "82 /content/data/brain_tumor_dataset/yes/Y242.JPG\n",
            "83 /content/data/brain_tumor_dataset/yes/Y89.JPG\n",
            "84 /content/data/brain_tumor_dataset/yes/Y78.jpg\n",
            "85 /content/data/brain_tumor_dataset/yes/Y163.JPG\n",
            "86 /content/data/brain_tumor_dataset/yes/Y41.jpg\n",
            "87 /content/data/brain_tumor_dataset/yes/Y113.JPG\n",
            "88 /content/data/brain_tumor_dataset/yes/Y259.JPG\n",
            "89 /content/data/brain_tumor_dataset/yes/Y76.jpg\n",
            "90 /content/data/brain_tumor_dataset/yes/Y51.jpg\n",
            "91 /content/data/brain_tumor_dataset/yes/Y50.JPG\n",
            "92 /content/data/brain_tumor_dataset/yes/Y99.JPG\n",
            "93 /content/data/brain_tumor_dataset/yes/Y180.jpg\n",
            "94 /content/data/brain_tumor_dataset/yes/Y245.jpg\n",
            "95 /content/data/brain_tumor_dataset/yes/Y253.JPG\n",
            "96 /content/data/brain_tumor_dataset/yes/Y109.JPG\n",
            "97 /content/data/brain_tumor_dataset/yes/Y185.jpg\n",
            "98 /content/data/brain_tumor_dataset/yes/Y21.jpg\n",
            "99 /content/data/brain_tumor_dataset/yes/Y181.jpg\n",
            "100 /content/data/brain_tumor_dataset/yes/Y3.jpg\n",
            "101 /content/data/brain_tumor_dataset/yes/Y186.jpg\n",
            "102 /content/data/brain_tumor_dataset/yes/Y22.jpg\n",
            "103 /content/data/brain_tumor_dataset/yes/Y12.jpg\n",
            "104 /content/data/brain_tumor_dataset/yes/Y105.jpg\n",
            "105 /content/data/brain_tumor_dataset/yes/Y56.jpg\n",
            "106 /content/data/brain_tumor_dataset/yes/Y2.jpg\n",
            "107 /content/data/brain_tumor_dataset/yes/Y246.JPG\n",
            "108 /content/data/brain_tumor_dataset/yes/Y45.JPG\n",
            "109 /content/data/brain_tumor_dataset/yes/Y55.jpg\n",
            "110 /content/data/brain_tumor_dataset/yes/Y154.jpg\n",
            "111 /content/data/brain_tumor_dataset/yes/Y102.jpg\n",
            "112 /content/data/brain_tumor_dataset/yes/Y195.JPG\n",
            "113 /content/data/brain_tumor_dataset/yes/Y11.jpg\n",
            "114 /content/data/brain_tumor_dataset/yes/Y33.jpg\n",
            "115 /content/data/brain_tumor_dataset/yes/Y164.JPG\n",
            "116 /content/data/brain_tumor_dataset/yes/Y157.JPG\n",
            "117 /content/data/brain_tumor_dataset/yes/Y255.JPG\n",
            "118 /content/data/brain_tumor_dataset/yes/Y249.JPG\n",
            "119 /content/data/brain_tumor_dataset/yes/Y30.jpg\n",
            "120 /content/data/brain_tumor_dataset/yes/Y161.JPG\n",
            "121 /content/data/brain_tumor_dataset/yes/Y160.JPG\n",
            "122 /content/data/brain_tumor_dataset/yes/Y117.JPG\n",
            "123 /content/data/brain_tumor_dataset/yes/Y40.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms, models"
      ],
      "metadata": {
        "id": "yvV-5zmyODno"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformations of the train and val data"
      ],
      "metadata": {
        "id": "I5kj-XoEiOM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomRotation(30),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       torchvision.transforms.Normalize(\n",
        "                                           mean=[0.485, 0.456, 0.406],\n",
        "                                           std=[0.229, 0.224, 0.225],),\n",
        "                                       ])\n",
        "test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomRotation(30),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      torchvision.transforms.Normalize(\n",
        "                                          mean=[0.485, 0.456, 0.406],\n",
        "                                          std=[0.229, 0.224, 0.225],),\n",
        "                                      ])"
      ],
      "metadata": {
        "id": "2aBWk-n4OEiF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(data_train,transform = train_transforms)\n",
        "test_data = datasets.ImageFolder(data_val,transform = test_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,shuffle=True,batch_size =16)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,shuffle=True,batch_size =16)"
      ],
      "metadata": {
        "id": "SwLQmgjYOJmf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGha6sdBOMYb",
        "outputId": "feb9ce05-841f-4d1e-f9a0-1da33982e529"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "mI65FKq4OP_o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download the ResNet-18 pre-trained on ImageNet dataset\n",
        "2. Freeze the model paramaters\n",
        "3. Modify the last fully connected layer to train on the Brain Tumor dataset"
      ],
      "metadata": {
        "id": "x3kRmo_LiUd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = models.resnet18(weights='IMAGENET1K_V1')\n",
        "for par in model1.parameters():\n",
        "  par.requires_grad = False\n",
        "\n",
        "fc_feat = model1.fc.in_features\n",
        "model1.fc = nn.Linear(fc_feat,2)\n",
        "\n",
        "model1 = model1.to(device)"
      ],
      "metadata": {
        "id": "_SVc95pGPcav"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model1.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)"
      ],
      "metadata": {
        "id": "eWAS_K0BRl_3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Test the model"
      ],
      "metadata": {
        "id": "tbb9bub3jAfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_accu = 0.0\n",
        "for epoch in range(50):  # loop over the dataset multiple times\n",
        "    print(\"Epoch\",epoch)\n",
        "    train_loss = 0.0\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    model1.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        #print(inputs.size(0))\n",
        "        labels = labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model1(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(\"loss\",loss)\n",
        "        # print statistics\n",
        "        train_loss += loss.item()*(inputs.size(0))\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    print(\"train_loss\",train_loss)\n",
        "    #print('Finished Training')\n",
        "\n",
        "\n",
        "    model1.eval()\n",
        "    for i, data1 in enumerate(test_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data1\n",
        "        #print(inputs.size(0))\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model1(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item()*(inputs.size(0))\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        correct += (pred == labels).sum()\n",
        "    val_loss = val_loss/len(test_loader.dataset)\n",
        "    print(\"val_loss\",val_loss)\n",
        "    acc = correct/len(test_loader.dataset)\n",
        "    print('acc',acc.item()*100)\n",
        "\n",
        "\n",
        "    if acc > best_accu:\n",
        "      best_accu = acc\n",
        "      print(f'Epoch:{epoch} Validation Accuracy:{acc:.4f}')\n",
        "      torch.save(model1.state_dict(),'/content/data/model1_weights.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9SYb0j9SZif",
        "outputId": "45025b45-b8cf-4ed8-85c1-d694ebe4d90d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "train_loss 0.843163135016493\n",
            "val_loss 0.6108142280578613\n",
            "acc 63.999998569488525\n",
            "Epoch:0 Validation Accuracy:0.6400\n",
            "Epoch 1\n",
            "train_loss 0.6227585663055552\n",
            "val_loss 0.5642387986183166\n",
            "acc 68.00000071525574\n",
            "Epoch:1 Validation Accuracy:0.6800\n",
            "Epoch 2\n",
            "train_loss 0.5089847771404999\n",
            "val_loss 0.5302653932571411\n",
            "acc 71.99999690055847\n",
            "Epoch:2 Validation Accuracy:0.7200\n",
            "Epoch 3\n",
            "train_loss 0.46812543918933774\n",
            "val_loss 0.4572082734107971\n",
            "acc 75.99999904632568\n",
            "Epoch:3 Validation Accuracy:0.7600\n",
            "Epoch 4\n",
            "train_loss 0.4293441842929483\n",
            "val_loss 0.42784019231796266\n",
            "acc 81.99999928474426\n",
            "Epoch:4 Validation Accuracy:0.8200\n",
            "Epoch 5\n",
            "train_loss 0.3688948299790838\n",
            "val_loss 0.39796730518341067\n",
            "acc 79.99999523162842\n",
            "Epoch 6\n",
            "train_loss 0.3376528447484735\n",
            "val_loss 0.3656394171714783\n",
            "acc 85.999995470047\n",
            "Epoch:6 Validation Accuracy:0.8600\n",
            "Epoch 7\n",
            "train_loss 0.3080551448126732\n",
            "val_loss 0.36115365982055664\n",
            "acc 87.99999952316284\n",
            "Epoch:7 Validation Accuracy:0.8800\n",
            "Epoch 8\n",
            "train_loss 0.3197653239290115\n",
            "val_loss 0.44526920080184934\n",
            "acc 74.00000095367432\n",
            "Epoch 9\n",
            "train_loss 0.3863865266292553\n",
            "val_loss 0.3903120231628418\n",
            "acc 81.99999928474426\n",
            "Epoch 10\n",
            "train_loss 0.33918001117377444\n",
            "val_loss 0.35561777353286744\n",
            "acc 85.999995470047\n",
            "Epoch 11\n",
            "train_loss 0.27827232584283856\n",
            "val_loss 0.3441064929962158\n",
            "acc 83.99999737739563\n",
            "Epoch 12\n",
            "train_loss 0.3176006723213666\n",
            "val_loss 0.40139503896236417\n",
            "acc 83.99999737739563\n",
            "Epoch 13\n",
            "train_loss 0.28168447866228413\n",
            "val_loss 0.3191597151756287\n",
            "acc 87.99999952316284\n",
            "Epoch 14\n",
            "train_loss 0.2407668977241798\n",
            "val_loss 0.4911613571643829\n",
            "acc 75.99999904632568\n",
            "Epoch 15\n",
            "train_loss 0.2950313476652935\n",
            "val_loss 0.40173058331012723\n",
            "acc 81.99999928474426\n",
            "Epoch 16\n",
            "train_loss 0.2279660187184517\n",
            "val_loss 0.4016206073760986\n",
            "acc 81.99999928474426\n",
            "Epoch 17\n",
            "train_loss 0.25987644798209514\n",
            "val_loss 0.40834315776824953\n",
            "acc 85.999995470047\n",
            "Epoch 18\n",
            "train_loss 0.33888189105564737\n",
            "val_loss 0.33981721609830856\n",
            "acc 79.99999523162842\n",
            "Epoch 19\n",
            "train_loss 0.3705527043988552\n",
            "val_loss 0.5680450728535652\n",
            "acc 63.999998569488525\n",
            "Epoch 20\n",
            "train_loss 0.26588739931877026\n",
            "val_loss 0.43081149101257327\n",
            "acc 85.999995470047\n",
            "Epoch 21\n",
            "train_loss 0.24548212016744567\n",
            "val_loss 0.3977281451225281\n",
            "acc 81.99999928474426\n",
            "Epoch 22\n",
            "train_loss 0.2703368972821776\n",
            "val_loss 0.3108426004648209\n",
            "acc 85.999995470047\n",
            "Epoch 23\n",
            "train_loss 0.29632992829595295\n",
            "val_loss 0.37459898114204404\n",
            "acc 81.99999928474426\n",
            "Epoch 24\n",
            "train_loss 0.2259087370974677\n",
            "val_loss 0.40690330617129805\n",
            "acc 75.99999904632568\n",
            "Epoch 25\n",
            "train_loss 0.258487521574415\n",
            "val_loss 0.3776139503717422\n",
            "acc 81.99999928474426\n",
            "Epoch 26\n",
            "train_loss 0.24784489306323046\n",
            "val_loss 0.32582547068595885\n",
            "acc 87.99999952316284\n",
            "Epoch 27\n",
            "train_loss 0.2616723526287549\n",
            "val_loss 0.36144920349121096\n",
            "acc 89.99999761581421\n",
            "Epoch:27 Validation Accuracy:0.9000\n",
            "Epoch 28\n",
            "train_loss 0.23445578528742486\n",
            "val_loss 0.35976111590862275\n",
            "acc 89.99999761581421\n",
            "Epoch 29\n",
            "train_loss 0.2031521705424257\n",
            "val_loss 0.3485050082206726\n",
            "acc 81.99999928474426\n",
            "Epoch 30\n",
            "train_loss 0.1984094825431044\n",
            "val_loss 0.37469170570373533\n",
            "acc 83.99999737739563\n",
            "Epoch 31\n",
            "train_loss 0.21559820092957596\n",
            "val_loss 0.4284678429365158\n",
            "acc 81.99999928474426\n",
            "Epoch 32\n",
            "train_loss 0.23274906676978313\n",
            "val_loss 0.38960813332349065\n",
            "acc 79.99999523162842\n",
            "Epoch 33\n",
            "train_loss 0.27181268076004067\n",
            "val_loss 0.36566067576408384\n",
            "acc 83.99999737739563\n",
            "Epoch 34\n",
            "train_loss 0.27681709980142527\n",
            "val_loss 0.4696473681926727\n",
            "acc 79.99999523162842\n",
            "Epoch 35\n",
            "train_loss 0.21369208050478855\n",
            "val_loss 0.363851877450943\n",
            "acc 83.99999737739563\n",
            "Epoch 36\n",
            "train_loss 0.2006698694135168\n",
            "val_loss 0.39811127066612245\n",
            "acc 87.99999952316284\n",
            "Epoch 37\n",
            "train_loss 0.20772662641379633\n",
            "val_loss 0.3568583059310913\n",
            "acc 91.99999570846558\n",
            "Epoch:37 Validation Accuracy:0.9200\n",
            "Epoch 38\n",
            "train_loss 0.20779454333735217\n",
            "val_loss 0.3520033416152\n",
            "acc 85.999995470047\n",
            "Epoch 39\n",
            "train_loss 0.21240860183397536\n",
            "val_loss 0.3722144412994385\n",
            "acc 83.99999737739563\n",
            "Epoch 40\n",
            "train_loss 0.22663437468664988\n",
            "val_loss 0.3770834214985371\n",
            "acc 81.99999928474426\n",
            "Epoch 41\n",
            "train_loss 0.18236186498491636\n",
            "val_loss 0.4148594278097153\n",
            "acc 81.99999928474426\n",
            "Epoch 42\n",
            "train_loss 0.23801065684098915\n",
            "val_loss 0.40921992003917695\n",
            "acc 81.99999928474426\n",
            "Epoch 43\n",
            "train_loss 0.2257071541154326\n",
            "val_loss 0.42303479194641114\n",
            "acc 85.999995470047\n",
            "Epoch 44\n",
            "train_loss 0.21585744472560037\n",
            "val_loss 0.2780938806012273\n",
            "acc 87.99999952316284\n",
            "Epoch 45\n",
            "train_loss 0.23240209102924234\n",
            "val_loss 0.454578800201416\n",
            "acc 81.99999928474426\n",
            "Epoch 46\n",
            "train_loss 0.2136247934672633\n",
            "val_loss 0.40898935824632643\n",
            "acc 83.99999737739563\n",
            "Epoch 47\n",
            "train_loss 0.19397773846910504\n",
            "val_loss 0.4449098202586174\n",
            "acc 79.99999523162842\n",
            "Epoch 48\n",
            "train_loss 0.2167147494155198\n",
            "val_loss 0.3875552670657635\n",
            "acc 83.99999737739563\n",
            "Epoch 49\n",
            "train_loss 0.23478410550819828\n",
            "val_loss 0.5789505597949028\n",
            "acc 69.9999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.load_state_dict(torch.load('/content/data/model1_weights.pt'))\n",
        "model1.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb9f27hFUN1O",
        "outputId": "57b2e8b0-d1d2-4f64-9158-5ab6125378e2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the trained model on sample image"
      ],
      "metadata": {
        "id": "WejaunxTjInU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "test_image1 = '/content/data/val/yes/Y101.jpg'\n",
        "test_image = '/content/data/val/no/11 no.jpg'\n",
        "test_img = Image.open(test_image)\n",
        "print(test_img)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.Resize((224, 224)),  # adjust to model's expected size\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "img_test = transform(test_img).unsqueeze(0)  # add batch dimension\n",
        "img_test = img_test.to(device)\n",
        "# Step 4: Run inference\n",
        "with torch.no_grad():\n",
        "    output = model1(img_test)\n",
        "    print(output)\n",
        "    _, prediction = torch.max(output,1)\n",
        "    print(prediction)\n",
        "\n",
        "print(f'Predicted class: {int(prediction)}')  # 0 or 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8jgVp26e38B",
        "outputId": "760a130c-fe90-432d-8d87-5e4de9961474"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x168 at 0x7CA25A75FFD0>\n",
            "tensor([[ 0.4182, -0.6014]], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dhwMxCXye-De"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}